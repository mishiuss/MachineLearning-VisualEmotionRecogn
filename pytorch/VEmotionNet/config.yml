dataset:
  train:
    local:
      data_root: D:\AVER\OMGEmotionChallenge-master\omg_TrainVideos\preproc/frames #D:\AVER\AFEW-VA\crop
      file_list: D:\AVER\OMGEmotionChallenge-master\omg_TrainVideos\preproc/train_data_with_landmarks.txt
    server:
      #data_root: /media/stc_ml_school/data/AFEW-VA/crop #D:\AVER\AFEW-VA\crop
      #file_list: /media/stc_ml_school/data/AFEW-VA/train_data_with_landmarks.txt
      data_root: /media/stc_ml_school/data/OMGEmotionChallenge/omg_TrainVideos/frames #D:\AVER\AFEW-VA\crop
      file_list: /media/stc_ml_school/data/OMGEmotionChallenge/omg_TrainVideos/train_data_with_landmarks.txt
  valid:
    local:
      data_root: D:\AVER\OMGEmotionChallenge-master\omg_ValidVideos\preproc/frames #D:\AVER\AFEW-VA\crop
      file_list: D:\AVER\OMGEmotionChallenge-master\omg_ValidVideos\preproc/test_data_with_landmarks.txt #D:\AVER\AFEW-VA\crop/test_data_with_landmarks.txt
    server:
      #data_root: /media/stc_ml_school/data/AFEW-VA/crop #D:\AVER\AFEW-VA\crop
      #file_list: /media/stc_ml_school/data/AFEW-VA/test_data_with_landmarks.txt #D:\AVER\AFEW-VA\crop/test_data_with_landmarks.txt
      data_root: /media/stc_ml_school/data/OMGEmotionChallenge/omg_ValidVideos/frames #D:\AVER\AFEW-VA\crop
      file_list: /media/stc_ml_school/data/OMGEmotionChallenge/omg_ValidVideos/valid_data_with_landmarks.txt #D:\AVER\AFEW-VA\crop/test_data_with_landmarks.txt

seed: 1234

net:
  type: ResNet
  depth: 18
  softmax_size: 2
  fine_tune: no

parser:
  max_num_clips: 0
  max_num_samples: 0

preproc:
  data_frame:
    width: 128
    height: 128
    depth: 1
  is_color: True
  mean: 127.5
  scale: 0.007843
  crop_size: 128
  aug:
    pad: 0
    color: BGR
    use_cutout: False
    use_mirroring: True
    use_random_crop: False
    use_center_crop: False
    use_random_gray: False

sampler:
  samples_is_randomize: no
  step_size_for_samples: 4

train_batcher:
  batch: 32 #batch size
  queue_size: 5
  disk_reader_process_num: 1

valid_batcher:
  batch: 32 #batch size
  queue_size: 5
  disk_reader_process_num: 1

batch_proc:
  use_pin_memory: yes
  use_async: yes

opt:
  type: SGD
  lr: 0.009 #initial learning rate
  momentum: 0.2
  weight_decay: 5.e-4 #initial weight decay

lr_scheduler:
  type: MultiCyclePolicy #SGDR, LRFinder, OneCyclePolicy
  gamma: 0.01
  use_linear_decay: yes
  scale_lr: [1., 1]
  scale_lr_fc: [1., 1]

train:
  cuda_device: 0 #cuda device id
  step_size: 100 #lr scheduler step size
  step_print: 100
  epoch_size: 50000 #epoch size
  max_iter: 10000000 #maximum iteration for training
  validate_iter: 1000
  snapshot_iter: 10000 #snapshot model frequency
  experiment_name: 'EmoV2_step4' #name for current experiment

losses:
  MSE:
    w: 1.

ini_net:
  local:  \\unid2face.stc\PublicB\kalinovskiy\ave_log\EmoV2_step4\EmoV2_step4_iter_14500.model
  server: /media/data/kalinovskiy/face_recognition/logs/AlexNet_CombinedMargin_5/AlexNet_CombinedMargin_5_15000.model

logging:
  log_dir:
    local:  D:/aver_log
    server: /media/stc_ml_school/logs
  tb_log_dir:
    local:  D:/aver_log
    server: /media/stc_ml_school/logs
  snapshot_dir:
    local: D:/aver_log
    server: /media/stc_ml_school/logs

test:
  dataset:
    data_root:
      local: D:\AVER\AFEW-VA\crop
      server: /media/data/stc-85k-a/faces
    test_file_list:
      local: D:\AVER\AFEW-VA\crop/test_data_with_landmarks.txt
      server: /media/data/kalinovskiy/train_file_list_85k.txt

  cuda_device: 0
  file_model: D:\aver_log\EmoV2_step40/EmoV2_step40_iter_25000.model
